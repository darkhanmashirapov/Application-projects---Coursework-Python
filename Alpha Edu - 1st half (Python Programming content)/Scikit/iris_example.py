# Файл 1: Реальный пример создания модели
"""
Этот файл объясняет процесс создания модели классификации
с пошаговым описанием каждого этапа на практическом примере.
"""

# Импортируем необходимые библиотеки
from sklearn.datasets import load_iris  # Загрузка датасета "Ирисы"
from sklearn.model_selection import train_test_split  # Разделение данных
from sklearn.ensemble import RandomForestClassifier  # Модель случайного леса
from sklearn.metrics import accuracy_score  # Метрика для оценки качества

# 1. Загрузка данных
"""
Загружаем встроенный набор данных Iris. Этот набор данных
содержит 150 образцов ирисов с четырьмя характеристиками
(длина и ширина лепестков и чашелистиков) и метками классов.
"""

"""
`load_iris()` - это встроенная функция библиотеки scikit-learn, которая загружает
один из самых известных учебных наборов данных для классификации: "Iris".

### Состав данных Iris
1. **Цель**: классифицировать три вида ирисов: Setosa, Versicolor, Virginica.
2. **Количество образцов**: 150 строк данных (по 50 для каждого класса).
3. **Признаки**:
   - Длина чашелистика (sepal length).[]
   - Ширина чашелистика (sepal width).[]
   - Длина лепестка (petal length).[]
   - Ширина лепестка (petal width).[]
4. **Целевые метки (классы)**:
   - 0: Setosa.
   - 1: Versicolor.
   - 2: Virginica.

Эти данные часто используются для обучения моделей классификации и
демонстрации алгоритмов.
"""

iris = load_iris()
X = iris.data  #? Признаки (длина и ширина лепестков/чашелистиков)
y = iris.target  #? Метки классов (виды ирисов: Setosa, Versicolor, Virginica)

# 2. Разделение данных на обучающую и тестовую выборки
"""
Мы делим данные на две части:
- Обучающая выборка (70%) используется для обучения модели. Это процесс,
  в котором алгоритм анализирует тренировочные данные и настраивает свои параметры.
- Тестовая выборка (30%) предназначена для проверки точности модели. Она оценивает,
  насколько хорошо модель может работать на данных, которые не были использованы
  во время обучения.

Зачем это нужно?
Если использовать одни и те же данные и для обучения, и для проверки, модель
может запомнить данные вместо того, чтобы научиться их обобщать. Это явление
называется переобучением (overfitting). Разделение данных помогает избежать
этой проблемы и проверить, насколько модель хорошо работает на новых данных.
"""
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 3. Создание и обучение модели
"""
Выбираем модель случайного леса (Random Forest). Случайный лес - это ансамблевая
модель, которая объединяет несколько решающих деревьев. Каждый "дерево" принимает
решение, основываясь на части данных, и результаты всех деревьев комбинируются
для более точного предсказания.

Как работает случайный лес?
1. В процессе обучения модель строит несколько деревьев решений (например, 100).
2. Каждое дерево обучается на случайной подвыборке данных и случайных признаках.
3. При прогнозировании модель использует "голосование" всех деревьев, чтобы
   определить итоговый класс (большинство голосов выигрывает).

Почему это эффективно?
Случайный лес уменьшает вероятность переобучения, так как деревья обучаются
независимо друг от друга. Это также делает модель устойчивой к шуму в данных.

- `n_estimators=100` означает, что используется 100 деревьев.
- `random_state=42` фиксирует случайность для воспроизводимости.
"""
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)  # Обучение модели на тренировочных данных

# 4. Прогнозирование
"""
После обучения модели используем её для предсказания меток
классов для тестовой выборки. На этом этапе модель применяет
знания, полученные на этапе обучения, к новым данным (X_test).
"""
y_pred = model.predict(X_test)

# 5. Оценка точности модели
"""
Оцениваем точность предсказаний модели, сравнивая их с реальными
значениями (y_test). Это позволяет понять, насколько хорошо
модель справляется с классификацией новых данных.

Метрика `accuracy_score` вычисляет отношение правильных предсказаний
к общему числу предсказаний. Например, точность 0.95 означает, что
модель правильно классифицировала 95% данных.
"""
accuracy = accuracy_score(y_test, y_pred)
print(f"Точность модели: {accuracy * 100:.2f}%")

# Заключение
"""
1. Данные были успешно разделены на обучающие и тестовые, чтобы
   избежать переобучения.
2. Модель случайного леса была обучена, продемонстрировав высокую
   точность на тестовых данных.
3. Этот процесс показывает полный цикл создания модели:
   от подготовки данных до её оценки.
"""
